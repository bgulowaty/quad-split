{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-18T16:30:55.493752Z",
     "start_time": "2023-08-18T16:30:55.296678Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import problexity as px\n",
    "from box import Box\n",
    "from loguru import logger as log\n",
    "from mlflow import MlflowClient\n",
    "from mlutils.datasets.dataset import Dataset\n",
    "from mlutils.mlflow.utils import get_run_params, terminate_run, finish_run_and_print_exception\n",
    "from sklearn.base import clone\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "from wrapt_timeout_decorator import timeout\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T16:30:57.824558Z",
     "start_time": "2023-08-18T16:30:55.343196Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def find_best_cutoff_for(dataset, dimension, minimal_split_percentage = 0.1, cutoff_function=px.f2):\n",
    "    possible_cutoffs = sorted(set(dataset.x[:, dimension]))\n",
    "    log.trace(\"Possible cutoffs = {}\", possible_cutoffs)\n",
    "    samples_in_cutoffs = [\n",
    "        Box({\n",
    "            'cutoff': cutoff,\n",
    "            'left': {\n",
    "                'x': dataset.x[dataset.x[:, dimension] <= cutoff],\n",
    "                'y': dataset.y[dataset.x[:, dimension] <= cutoff],\n",
    "            },\n",
    "            'right': {\n",
    "                'x': dataset.x[dataset.x[:, dimension] > cutoff],\n",
    "                'y': dataset.y[dataset.x[:, dimension] > cutoff],\n",
    "            }\n",
    "         })\n",
    "        for cutoff in possible_cutoffs\n",
    "    ]\n",
    "\n",
    "    def should_pass(cutoff_samples):\n",
    "        left_size = len(cutoff_samples.left.x)\n",
    "        right_size = len(cutoff_samples.right.x)\n",
    "        \n",
    "        min_split_size = len(dataset.x) * minimal_split_percentage\n",
    "\n",
    "        log.debug(\"Checking left and right split sizes l={} r={}, total_dataset_size={}, test={}{}\", left_size, right_size, len(dataset.x),  left_size > min_split_size,  right_size > minimal_split_percentage )\n",
    "\n",
    "        return left_size >= min_split_size and right_size >= min_split_size\n",
    "\n",
    "    samples_in_cutoffs_filtered = [\n",
    "        cutoff_samples for cutoff_samples in samples_in_cutoffs if should_pass(cutoff_samples)\n",
    "    ]\n",
    "    \n",
    "    log.trace(\"Cutoffs filtered = {}\", samples_in_cutoffs_filtered)\n",
    "\n",
    "    for it in samples_in_cutoffs_filtered:\n",
    "        try:\n",
    "            log.debug(\"Computing complexity for {}\", it)\n",
    "            left_complexities = []\n",
    "            for label in np.unique(it.left.y):\n",
    "                log.debug(\"Main label {}\", label)\n",
    "                ovo_y = it.left.y.copy()\n",
    "                ovo_y[ovo_y != label] = 0\n",
    "                ovo_y[ovo_y == label] = 1\n",
    "                if len(np.unique(ovo_y)) == 1:\n",
    "                    continue\n",
    "                left_complexity = cutoff_function(it.left.x, ovo_y)\n",
    "                left_complexities.append(left_complexity)\n",
    "\n",
    "\n",
    "            right_complexities = []\n",
    "            for label in np.unique(it.right.y):\n",
    "                log.debug(\"Main label {}\", label)\n",
    "                ovo_y = it.left.y.copy()\n",
    "                ovo_y[ovo_y != label] = 0\n",
    "                ovo_y[ovo_y == label] = 1\n",
    "                if len(np.unique(ovo_y)) == 1:\n",
    "                    continue\n",
    "                right_complexity = cutoff_function(it.left.x, ovo_y)\n",
    "                right_complexities.append(right_complexity)\n",
    "                \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "            log.exception(e)\n",
    "            return None\n",
    "\n",
    "        it.left_complexity = np.mean(left_complexities)\n",
    "        it.right_complexity = np.mean(right_complexities)\n",
    "\n",
    "    if not samples_in_cutoffs_filtered:\n",
    "        return None\n",
    "    lowest_complexity = min(samples_in_cutoffs_filtered, key = lambda it: it.left_complexity + it.right_complexity)\n",
    "\n",
    "    if lowest_complexity is None:\n",
    "        return None\n",
    "\n",
    "\n",
    "    return lowest_complexity.cutoff, lowest_complexity.left_complexity + lowest_complexity.right_complexity\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T16:30:57.849968Z",
     "start_time": "2023-08-18T16:30:57.821707Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def recursive_cutoff(dataset, current_conditions=None, recursion_level=0, min_samples = 10, recursion_limit = 4, minimal_split_percentage = 0.1, complexity_measure = px.f2):\n",
    "    log.info(\"Recursion level = {}\", recursion_level)\n",
    "    \n",
    "    if current_conditions is None:\n",
    "        current_conditions = list()\n",
    "\n",
    "    if recursion_limit != -1 and recursion_level >= recursion_limit:\n",
    "        log.info(\"Recursion limit reached {}\", recursion_level)\n",
    "        return {\" and \".join(current_conditions)}\n",
    "    recursion_level = recursion_level + 1\n",
    "    log.debug(\"Recursion level = {}\", recursion_level)\n",
    "\n",
    "    if len(dataset.x) < min_samples:\n",
    "        log.info(\"min_samples limit reached {} < {}\", len(dataset.x), min_samples)\n",
    "        return {\" and \".join(current_conditions)}\n",
    "\n",
    "    features_count = dataset.x.shape[1]\n",
    "\n",
    "    best_cutoff_by_dimension = {}\n",
    "\n",
    "    for feature_idx in range(features_count):\n",
    "        cutoff_and_value = find_best_cutoff_for(Box(x=dataset.x, y=dataset.y), feature_idx, minimal_split_percentage=minimal_split_percentage, cutoff_function=complexity_measure)\n",
    "        if cutoff_and_value is None:\n",
    "            continue\n",
    "\n",
    "        cutoff, value = cutoff_and_value\n",
    "\n",
    "        best_cutoff_by_dimension[feature_idx] = {\n",
    "            'cutoff': cutoff,\n",
    "            'value': value\n",
    "        }\n",
    "\n",
    "    if not best_cutoff_by_dimension:\n",
    "        log.debug(\"No best cutoff found\")\n",
    "        return {\" and \".join(current_conditions)}\n",
    "\n",
    "    best_cutoff_entry = min(best_cutoff_by_dimension.items(), key=lambda it: it[1]['cutoff'])\n",
    "    best_cutoff_dimension = best_cutoff_entry[0]\n",
    "    best_cutoff = best_cutoff_entry[1]['cutoff']\n",
    "    best_cutoff_value = best_cutoff_entry[1]['value']\n",
    "\n",
    "    log.debug(\"Best cutoff value = {} ({} at dim {})\", best_cutoff_value, best_cutoff, best_cutoff_dimension)\n",
    "\n",
    "    left_conditions = f\"col{best_cutoff_dimension} <= {best_cutoff}\"\n",
    "    right_conditions = f\"col{best_cutoff_dimension} > {best_cutoff}\"\n",
    "    log.debug(left_conditions)\n",
    "    log.debug(right_conditions)\n",
    "\n",
    "    left_indicies = dataset.x[:, best_cutoff_dimension] <= best_cutoff\n",
    "    right_indicies = dataset.x[:, best_cutoff_dimension] > best_cutoff\n",
    "\n",
    "    left_statements = recursive_cutoff(Box(x=dataset.x[left_indicies], y=dataset.y[left_indicies]), current_conditions + [left_conditions], recursion_level + 1)\n",
    "    right_statements = recursive_cutoff(Box(x=dataset.x[right_indicies], y=dataset.y[right_indicies]), current_conditions + [right_conditions], recursion_level + 1)\n",
    "    log.debug(\"Left statements {}\", left_statements)\n",
    "    log.debug(\"Right statments {}\", right_statements)\n",
    "\n",
    "    return left_statements.union(right_statements)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T16:30:57.880050Z",
     "start_time": "2023-08-18T16:30:57.854519Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def as_classifier(clf_by_rule):\n",
    "    def predict(X):\n",
    "        df = pd.DataFrame(X, columns=[f\"col{i}\" for i in range(X.shape[1])])\n",
    "\n",
    "        for rule, clf in clf_by_rule.items():\n",
    "            idx_to_predict = df.query(rule).index\n",
    "            to_predict = df.loc[idx_to_predict] \\\n",
    "                .drop('prediction', axis=1, errors='ignore') \\\n",
    "                .drop('rule', axis=1, errors='ignore') \\\n",
    "                .to_numpy()\n",
    "\n",
    "            if len(to_predict) == 0:\n",
    "                continue\n",
    "\n",
    "            df.loc[idx_to_predict, 'prediction'] = clf.predict(df.loc[df.query(rule).index] \\\n",
    "                                                               .drop('prediction', axis=1, errors='ignore') \\\n",
    "                                                               .drop('rule', axis=1, errors='ignore') \\\n",
    "                                                               .to_numpy())\n",
    "            df.loc[df.query(rule).index, 'rule'] = rule\n",
    "\n",
    "        return df.prediction.to_numpy()\n",
    "\n",
    "    return Box({\n",
    "        \"predict\": predict\n",
    "    })"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T16:30:57.911070Z",
     "start_time": "2023-08-18T16:30:57.881433Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def train_quad_clf(train_x, train_y, base_clf_id = \"perceptron\", min_samples = 10, recursion_limit = -1, minimal_split_percentage = 0.1, complexity_measure = \"f2\"):\n",
    "    base_clf = {\n",
    "        \"perceptron\": Perceptron(random_state=42),\n",
    "        \"dt\": DecisionTreeClassifier(random_state=42),\n",
    "        \"knn\": KNeighborsClassifier(),\n",
    "        \"nb\": GaussianNB(),\n",
    "    }.get(base_clf_id)\n",
    "    \n",
    "    complexity_measure_func = {\n",
    "        \"f2\": px.f2,\n",
    "        \"f4\": px.f4,\n",
    "        \"l2\": px.l2,\n",
    "        \"l3\": px.l3,\n",
    "        \"n1\": px.n1,\n",
    "        \"n2\": px.n2,\n",
    "        \"n3\": px.n3,\n",
    "        \"t1\": px.t1, # slow\n",
    "        \"clsCoef\": px.clsCoef,\n",
    "        \"density\": px.density,    \n",
    "    }.get(complexity_measure)\n",
    "    \n",
    "    \n",
    "    statements = recursive_cutoff(Box(\n",
    "        x=train_x,\n",
    "        y=train_y\n",
    "    ), min_samples=min_samples, recursion_limit=recursion_limit, minimal_split_percentage=minimal_split_percentage, complexity_measure=complexity_measure_func)\n",
    "    \n",
    "    log.info(\"Statements {}\", statements)\n",
    "    \n",
    "    clf_by_rules = {}\n",
    "    x_for_indices_calculation = pd.DataFrame(train_x)\n",
    "    for col in range(x_for_indices_calculation.shape[1]):\n",
    "        x_for_indices_calculation[f\"col{col}\"] = x_for_indices_calculation[col]\n",
    "    indices_by_each_statement = {\n",
    "        query: x_for_indices_calculation.query(query).index for query in statements\n",
    "    }\n",
    "    \n",
    "    for query, idx in indices_by_each_statement.items():\n",
    "        x_train = train_x[idx]\n",
    "        y_train = train_y[idx]\n",
    "        \n",
    "        log.debug(len(x_train))\n",
    "        log.debug(query)\n",
    "    \n",
    "        if len(np.unique(y_train)) == 1:\n",
    "            clf_by_rules[query] = DummyClassifier(strategy=\"constant\", constant=y_train[0]).fit(x_train, y_train)\n",
    "        else:\n",
    "            clf = clone(base_clf)\n",
    "            clf.fit(x_train, y_train)\n",
    "            clf_by_rules[query] = clf\n",
    "    \n",
    "    return as_classifier(clf_by_rules)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T16:30:57.938093Z",
     "start_time": "2023-08-18T16:30:57.910108Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def do_experiment_v1(run_id):\n",
    "    client = MlflowClient(tracking_uri=\"sqlite:///experiments.db\")\n",
    "    param = get_run_params(run_id, client)\n",
    "    from loguru import logger\n",
    "    logger.info(param)\n",
    "\n",
    "    try:\n",
    "        # DATA and preprocessing\n",
    "        train_path = param.train_path.replace('tra', 'tst')\n",
    "        name = param.train_path.split(\"/\")[-1].split('-')[0]\n",
    "        dataset = Dataset.read_dataset(param.train_path, train_path, name) \\\n",
    "            .encode_x_to_labels() \\\n",
    "            .encode_y_to_numeric_labels()\n",
    "\n",
    "        # model\n",
    "        model = timeout(200)(train_quad_clf)(dataset.train.x, dataset.train.y, base_clf_id=param.base_clf, min_samples=int(param.min_samples), minimal_split_percentage=float(param.min_split_percentage), complexity_measure=param.complexity_measure)\n",
    "        \n",
    "\n",
    "        acc = accuracy_score(model.predict(dataset.test.x), dataset.test.y)\n",
    "        client.log_metric(run_id, \"acc\", acc)\n",
    "        log.info(\"Acc = {}\", acc)\n",
    "\n",
    "        terminate_run(run_id, client=client)\n",
    "    except Exception as e:\n",
    "        finish_run_and_print_exception(run_id, e, client = client)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T16:54:11.020582Z",
     "start_time": "2023-08-18T16:54:09.893341Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def do_experiment_base(run_id):\n",
    "    client = MlflowClient(tracking_uri=\"sqlite:///experiments.db\")\n",
    "    param = get_run_params(run_id, client=client)\n",
    "    from loguru import logger\n",
    "    logger.info(param)\n",
    "\n",
    "    try:\n",
    "        # DATA and preprocessing\n",
    "        train_path = param.train_path.replace('tra', 'tst')\n",
    "        name = param.train_path.split(\"/\")[-1].split('-')[0]\n",
    "        dataset = Dataset.read_dataset(param.train_path, train_path, name) \\\n",
    "            .encode_x_to_labels() \\\n",
    "            .encode_y_to_numeric_labels()\n",
    "\n",
    "        # model\n",
    "        dt = DecisionTreeClassifier(random_state=42)\n",
    "        perceptron = Perceptron(random_state=42)\n",
    "        random_forest = RandomForestClassifier(random_state=42)\n",
    "        \n",
    "        dt.fit(dataset.train.x, dataset.train.y)\n",
    "        perceptron.fit(dataset.train.x, dataset.train.y)\n",
    "        random_forest.fit(dataset.train.x, dataset.train.y)\n",
    "        \n",
    "        client.log_metric(run_id, \"dt_acc\", accuracy_score(dt.predict(dataset.test.x), dataset.test.y))\n",
    "        client.log_metric(run_id, \"rf_acc\", accuracy_score(random_forest.predict(dataset.test.x), dataset.test.y))\n",
    "        client.log_metric(run_id, \"perceptron_acc\", accuracy_score(perceptron.predict(dataset.test.x), dataset.test.y))\n",
    "\n",
    "        terminate_run(run_id, client=client)\n",
    "    except Exception as e:\n",
    "        finish_run_and_print_exception(run_id, e, client = client)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T16:54:15.672752Z",
     "start_time": "2023-08-18T16:54:15.645552Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "log.remove(0)\n",
    "log.add(sys.stderr, level=\"INFO\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T16:30:58.017815Z",
     "start_time": "2023-08-18T16:30:57.993152Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

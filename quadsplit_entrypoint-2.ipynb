{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T14:16:48.611914Z",
     "start_time": "2024-07-27T14:16:48.584928Z"
    }
   },
   "source": [
    "import scipy\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-07-27T14:16:48.653668Z",
     "start_time": "2024-07-27T14:16:48.633651Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import problexity as px\n",
    "from box import Box\n",
    "from loguru import logger as log\n",
    "import mlflow\n",
    "\n",
    "from mlflow import MlflowClient\n",
    "from datasetz.core.load_dataset import load_embedded_dataset\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit\n",
    "from mlutils.mlflow.utils import get_run_params, terminate_run, finish_run_and_print_exception\n",
    "from sklearn.base import clone\n",
    "from mlutils.scikit.ovo import ovo\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "from wrapt_timeout_decorator import timeout\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from quadsplits.quadsplits import recursive_cutoff\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from datasetz.core.load_dataset import load_embedded_dataset\n",
    "from imblearn.metrics import geometric_mean_score, classification_report_imbalanced\n",
    "from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score, f1_score\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from mlutils.scikit.utils import is_fitted\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from mlutils.scikit.utils import is_fitted\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-07-27T14:16:48.672935Z",
     "start_time": "2024-07-27T14:16:48.654740Z"
    }
   },
   "source": [
    "DT_PARAMS = {'ccp_alpha': 0.011538226894236229, 'criterion': 'gini', 'max_features': None}\n",
    "DT_PARAMS_WO_DEPTH = {'criterion': 'gini', 'max_features': None}\n",
    "RF_PARAMS = {'n_estimators': 32}"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T14:16:48.692856Z",
     "start_time": "2024-07-27T14:16:48.674656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_imb_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        'balacc': balanced_accuracy_score(y_true, y_pred),\n",
    "        'gmean': geometric_mean_score(y_true, y_pred),\n",
    "        'f1': f1_score(y_true, y_pred)\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T14:16:48.720532Z",
     "start_time": "2024-07-27T14:16:48.701887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_and_log_classification_metrics(y_true, y_pred, client, run_id, prefix = \"\"):\n",
    "    conf_matrix = calculate_confusion_matrix(y_true, y_pred)\n",
    "    cls_report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    imb_cls_report = classification_report_imbalanced(y_true, y_pred, output_dict=True)\n",
    "    imb_metrics = calculate_imb_metrics(y_true, y_pred)\n",
    "\n",
    "    client.log_dict(run_id, cls_report, f'{prefix}cls_report.json')\n",
    "    client.log_dict(run_id, imb_cls_report, f'{prefix}imb_cls_report.json')\n",
    "\n",
    "    for k, v in {**conf_matrix, **imb_metrics}.items():\n",
    "        client.log_metric(run_id, f\"{prefix}{k}\", v)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-07-27T14:19:20.603573Z",
     "start_time": "2024-07-27T14:19:20.570999Z"
    }
   },
   "source": [
    "def calculate_metrics_dt(model):\n",
    "    return {\n",
    "        'n_leaves': model.get_n_leaves(),\n",
    "        'depth': model.get_depth()\n",
    "    }\n",
    "\n",
    "def calculate_metrics_qs(model):\n",
    "    clf_by_rules = model.clf_by_rules_\n",
    "\n",
    "    clfs = clf_by_rules.values()\n",
    "\n",
    "    print(clfs)\n",
    "    dummy_classifiers_no = len([clf for clf in clfs if isinstance(clf, DummyClassifier)])\n",
    "\n",
    "    dts = [calculate_metrics_dt(clf) for clf in clfs if isinstance(clf, DecisionTreeClassifier)]\n",
    "    \n",
    "    no_of_predicates = np.array([rule.count(\"and\")+1 for rule in clf_by_rules.keys()])\n",
    "    \n",
    "    return {\n",
    "        \"dts\": dts,\n",
    "        \"dummy_clfs\": dummy_classifiers_no,\n",
    "        \"all_clfs\": len(clfs),\n",
    "        \"complex_clfs\": len(clfs) - dummy_classifiers_no,\n",
    "        \"rules_no\": len(clf_by_rules),\n",
    "        \"rules\": no_of_predicates.tolist(),\n",
    "        \"no_of_predicates_avg\": no_of_predicates.mean(),\n",
    "        \"no_of_predicates_median\": np.median(no_of_predicates),\n",
    "        \"no_of_predicates_max\": np.max(no_of_predicates),\n",
    "        \"no_of_predicates_min\": np.min(no_of_predicates)\n",
    "        \n",
    "    }\n",
    "\n",
    "def calculate_confusion_matrix(y_pred, y_true):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_pred, y_true).ravel()\n",
    "\n",
    "    return {\n",
    "        'tn': tn,\n",
    "        'fp': fp,\n",
    "        'fn': fn,\n",
    "        'tp': tp\n",
    "    }\n",
    "def get_params_and_client(run_id):\n",
    "    client = MlflowClient(tracking_uri=\"http://192.168.1.181:5010\")\n",
    "    mlflow.set_tracking_uri(\"http://192.168.1.181:5010\")\n",
    "    params = get_run_params(run_id, client)\n",
    "    params.should_take_test = params.should_take_test.lower() == \"true\"\n",
    "    params.data_shuffle_random_state = int(params.data_shuffle_random_state)\n",
    "    return params, client\n",
    "\n",
    "\n",
    "def get_dataset(params):\n",
    "    dataset = load_embedded_dataset('keel-binary-fast', params.dataset).encode_x_to_labels()\n",
    "\n",
    "    x_whole = dataset.x()\n",
    "    y_whole = dataset.y()\n",
    "\n",
    "    sss = StratifiedShuffleSplit(random_state=params.data_shuffle_random_state, n_splits=1, test_size=0.5)\n",
    "    train_idx, test_idx = next(sss.split(x_whole, y_whole))\n",
    "\n",
    "    if params.should_take_test:\n",
    "        x_train = x_whole[test_idx]\n",
    "        y_train = y_whole[test_idx]\n",
    "\n",
    "        x_test = x_whole[train_idx]\n",
    "        y_test = y_whole[train_idx]\n",
    "    else:\n",
    "        x_train = x_whole[train_idx]\n",
    "        y_train = y_whole[train_idx]\n",
    "\n",
    "        x_test = x_whole[test_idx]\n",
    "        y_test = y_whole[test_idx]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-07-27T14:16:48.762108Z",
     "start_time": "2024-07-27T14:16:48.744243Z"
    }
   },
   "source": [
    "def exclude_indices(arr, indices):\n",
    "    return arr[~np.isin(np.arange(arr.shape[0]), indices)]\n",
    "\n",
    "def find_nearest_neighbors_indices(arr, point, n):\n",
    "    nn = NearestNeighbors(n_neighbors=n)\n",
    "    nn.fit(arr)\n",
    "    return nn.kneighbors([point], n)[1].reshape(-1)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-07-27T14:16:48.783106Z",
     "start_time": "2024-07-27T14:16:48.763557Z"
    }
   },
   "source": [
    "def as_classifier_from_rf(clf_by_rule, rf):\n",
    "    def predict(X):\n",
    "        df = pd.DataFrame(X, columns=[f\"col{i}\" for i in range(X.shape[1])])\n",
    "\n",
    "        for rule, clf in clf_by_rule.items():\n",
    "            idx_to_predict = df.query(rule).index\n",
    "            to_predict = df.loc[idx_to_predict] \\\n",
    "                .drop('prediction', axis=1, errors='ignore') \\\n",
    "                .drop('rule', axis=1, errors='ignore') \\\n",
    "                .to_numpy()\n",
    "\n",
    "            if len(to_predict) == 0:\n",
    "                continue\n",
    "\n",
    "            df.loc[idx_to_predict, 'prediction'] = clf.predict(df.loc[df.query(rule).index] \\\n",
    "                                                               .drop('prediction', axis=1, errors='ignore') \\\n",
    "                                                               .drop('rule', axis=1, errors='ignore') \\\n",
    "                                                               .to_numpy())\n",
    "            df.loc[df.query(rule).index, 'rule'] = rule\n",
    "\n",
    "        return df.prediction.to_numpy()\n",
    "\n",
    "    return Box({\n",
    "        \"clf_by_rule\": clf_by_rule,\n",
    "        \"predict\": predict\n",
    "    })"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-07-27T14:16:48.802154Z",
     "start_time": "2024-07-27T14:16:48.783936Z"
    }
   },
   "source": [
    "def as_classifier(clf_by_rule):\n",
    "    def predict(X):\n",
    "        df = pd.DataFrame(X, columns=[f\"col{i}\" for i in range(X.shape[1])])\n",
    "\n",
    "        for rule, clf in clf_by_rule.items():\n",
    "            idx_to_predict = df.query(rule).index\n",
    "            to_predict = df.loc[idx_to_predict] \\\n",
    "                .drop('prediction', axis=1, errors='ignore') \\\n",
    "                .drop('rule', axis=1, errors='ignore') \\\n",
    "                .to_numpy()\n",
    "\n",
    "            if len(to_predict) == 0:\n",
    "                continue\n",
    "\n",
    "            df.loc[idx_to_predict, 'prediction'] = clf.predict(df.loc[df.query(rule).index] \\\n",
    "                                                               .drop('prediction', axis=1, errors='ignore') \\\n",
    "                                                               .drop('rule', axis=1, errors='ignore') \\\n",
    "                                                               .to_numpy())\n",
    "            df.loc[df.query(rule).index, 'rule'] = rule\n",
    "\n",
    "        return df.prediction.to_numpy()\n",
    "\n",
    "    return Box({\n",
    "        \"clf_by_rule\": clf_by_rule,\n",
    "        \"predict\": predict\n",
    "    })"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-07-27T14:16:48.821623Z",
     "start_time": "2024-07-27T14:16:48.803137Z"
    }
   },
   "source": [
    "def dont_invoke_for_single_class(func):\n",
    "    def wrapped(x, y):\n",
    "        if len(np.unique(y)) == 1:\n",
    "            return 0\n",
    "        \n",
    "        return func(x, y)\n",
    "\n",
    "    return wrapped\n"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-07-27T14:16:48.840341Z",
     "start_time": "2024-07-27T14:16:48.822409Z"
    }
   },
   "source": [
    "def wrap_in_ovo(func):\n",
    "    def wrapped(x, y):\n",
    "        return np.mean(ovo(func, x, y))\n",
    "\n",
    "    return wrapped\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-07-27T14:16:48.858907Z",
     "start_time": "2024-07-27T14:16:48.841264Z"
    }
   },
   "source": [
    "\n",
    "COMPLEXITY_METRICS = {k: dont_invoke_for_single_class(v) for k, v in {\n",
    "    'f2': px.f2,\n",
    "    't4': px.t4,\n",
    "    'c1': px.c1,\n",
    "    'n3': px.n3,\n",
    "    'l2': px.l2,\n",
    "    'density': px.density,\n",
    "}.items()}\n",
    "\n",
    "MODELS = {\n",
    "    \"knn\": KNeighborsClassifier(n_neighbors=3),\n",
    "    \"bayes\": GaussianNB(),\n",
    "    \"dt\": DecisionTreeClassifier(random_state=42, **DT_PARAMS),\n",
    "    \"svm\": LinearSVC(random_state=42)\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-07-27T14:16:48.884745Z",
     "start_time": "2024-07-27T14:16:48.861902Z"
    }
   },
   "source": [
    "def train_quad_clf(train_x, train_y, base_clf = Perceptron(random_state=42), min_samples = 10, recursion_limit = -1, minimal_split_percentage = 0.1, complexity_measure = px.f2, oversampling_in_splitting=None, neighbors_in_learning = None, log_metric = lambda x, y: None):\n",
    "    \n",
    "    if oversampling_in_splitting == \"SMOTE\":\n",
    "        smote = SMOTE(random_state=42, k_neighbors=1)\n",
    "        \n",
    "        def resample_x_y(x,y):\n",
    "            if (not (np.unique(y, return_counts=True)[1] > 3).all()) or len(np.unique(y)) <= 1:\n",
    "                return x, y\n",
    "            else: \n",
    "                log.info(\"Will resample with size {} {} and classes = {}\", len(x), len(y), np.unique(y))\n",
    "                return smote.fit_resample(x, y)\n",
    "        \n",
    "        oversampling_in_splitting_function = resample_x_y\n",
    "    else:\n",
    "        oversampling_in_splitting_function = lambda x,y: (x,y)\n",
    "    \n",
    "    statements = {}\n",
    "    \n",
    "    while (not statements and minimal_split_percentage > 0.1) or (len(statements) == 0) or (len(statements) == 1  and '' in statements):\n",
    "        statements = recursive_cutoff(Box(\n",
    "            x=train_x,\n",
    "            y=train_y\n",
    "        ), min_samples=min_samples, recursion_limit=recursion_limit, minimal_split_percentage=minimal_split_percentage, complexity_measure=complexity_measure, oversampling_function=oversampling_in_splitting_function)\n",
    "        minimal_split_percentage = minimal_split_percentage - minimal_split_percentage * 0.1\n",
    "        log.info(\"Stepping down minimial split percentage = {}\", minimal_split_percentage)\n",
    "    \n",
    "    log.info(\"Statements {}\", statements)\n",
    "    \n",
    "    if not statements:\n",
    "        log.info(\"No statements! Training base clf\")\n",
    "        clf = clone(base_clf)\n",
    "        clf.fit(train_x, train_y)\n",
    "        log_metric(\"no_statements\", True)\n",
    "        return clf\n",
    "    \n",
    "    log_metric(\"actual_min_split_percentage\", minimal_split_percentage)\n",
    "    if statements:\n",
    "        log_metric(\"statements_size\", len(statements))\n",
    "    \n",
    "    clf_by_rules = {}\n",
    "    x_for_indices_calculation = pd.DataFrame(train_x)\n",
    "    for col in range(x_for_indices_calculation.shape[1]):\n",
    "        x_for_indices_calculation[f\"col{col}\"] = x_for_indices_calculation[col]\n",
    "    indices_by_each_statement = {\n",
    "        query: x_for_indices_calculation.query(query).index for query in statements\n",
    "    }\n",
    "    \n",
    "    simple_areas = 0\n",
    "    for query, idx in indices_by_each_statement.items():\n",
    "        x_train = train_x[idx]\n",
    "        y_train = train_y[idx]\n",
    "        \n",
    "        log.info(\"Before enhancing with nn = {}\", len(x_train))\n",
    "        \n",
    "        if neighbors_in_learning is not None:\n",
    "            centroid = x_train.mean(axis=0)\n",
    "            nn_indices = find_nearest_neighbors_indices(exclude_indices(train_x, idx), centroid, neighbors_in_learning)\n",
    "            x_train = np.append(x_train, train_x[nn_indices], axis=0)\n",
    "            y_train = np.append(y_train, train_y[nn_indices], axis=0)\n",
    "\n",
    "            log.info(\"After enhancing with nn = {}\", len(x_train))\n",
    "            # log.info(y_train)\n",
    "    \n",
    "        if len(np.unique(y_train)) == 1:\n",
    "            clf_by_rules[query] = DummyClassifier(strategy=\"constant\", constant=y_train[0]).fit(x_train, y_train)\n",
    "            simple_areas = simple_areas + 1\n",
    "        else:\n",
    "            clf = clone(base_clf)\n",
    "            clf.fit(x_train, y_train)\n",
    "            clf_by_rules[query] = clf\n",
    "    \n",
    "    log_metric(\"simple_areas\", simple_areas)\n",
    "    \n",
    "    return as_classifier(clf_by_rules)"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-07-27T14:16:48.904191Z",
     "start_time": "2024-07-27T14:16:48.885790Z"
    }
   },
   "source": [
    "def find_best_tree(rf, x, y):\n",
    "    best_score = 0\n",
    "    best_tree = None\n",
    "    for tree in rf.estimators_:\n",
    "        tree_preds = tree.predict(x)\n",
    "        acc = accuracy_score(tree_preds, y)\n",
    "        if acc > best_score:\n",
    "            best_tree = tree\n",
    "            best_score = acc\n",
    "\n",
    "    return best_tree, best_score"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-07-27T14:16:48.923370Z",
     "start_time": "2024-07-27T14:16:48.905285Z"
    }
   },
   "source": [
    "def rf_complexity_measure(rf):\n",
    "\n",
    "    def measure(x, y):\n",
    "        tree, acc = find_best_tree(rf, x, y)\n",
    "    \n",
    "        return 1 - acc\n",
    "\n",
    "    \n",
    "    \n",
    "    return measure"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-07-27T14:16:48.949062Z",
     "start_time": "2024-07-27T14:16:48.924227Z"
    }
   },
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "\n",
    "class QuadSplitClassifier(BaseEstimator, ClassifierMixin):\n",
    "        \n",
    "    def __init__(self, minimal_split_percentage, min_samples, complexity_measure, base_clf=None, recursion_limit=20, rf_to_explain=None):\n",
    "        self.minimal_split_percentage = minimal_split_percentage\n",
    "        self.min_samples = min_samples\n",
    "        self.recursion_limit = recursion_limit\n",
    "        self.complexity_measure = complexity_measure\n",
    "        self.base_clf = base_clf\n",
    "        self.rf_to_explain = rf_to_explain\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        x, y = check_X_y(x, y)\n",
    "\n",
    "\n",
    "        assert self.base_clf is not None or self.rf_to_explain is not None\n",
    "        assert self.minimal_split_percentage < 0.5\n",
    "        assert self.minimal_split_percentage > 0.1\n",
    "        assert isinstance(self.minimal_split_percentage, float)\n",
    "        assert self.min_samples >= 1\n",
    "        assert isinstance(self.min_samples, int)\n",
    "        \n",
    "        oversampling_in_splitting_function = lambda x,y: (x,y)\n",
    "        statements = {}\n",
    "\n",
    "        minimal_split_percentage = self.minimal_split_percentage\n",
    "        while (not statements and self.minimal_split_percentage > 0.1) or (len(statements) == 0) or (len(statements) == 1  and '' in statements):\n",
    "            statements = recursive_cutoff(Box(\n",
    "                x=x,\n",
    "                y=y\n",
    "            ), min_samples=self.min_samples, recursion_limit=self.recursion_limit, minimal_split_percentage=minimal_split_percentage, complexity_measure=self.complexity_measure, oversampling_function=oversampling_in_splitting_function)\n",
    "            minimal_split_percentage = minimal_split_percentage - minimal_split_percentage * 0.1\n",
    "            log.info(\"Stepping down minimial split percentage = {}\", minimal_split_percentage)\n",
    "\n",
    "        log.info(\"Statements {}\", statements)\n",
    "        \n",
    "        if not statements:\n",
    "            if self.rf_to_explain is not None:\n",
    "                log.info(\"No statements! getting best tree\")\n",
    "                tree, acc = find_best_tree(self.rf_to_explain, x, y)\n",
    "                return tree\n",
    "            log.info(\"No statements! Training base clf\")\n",
    "            clf = clone(self.base_clf)\n",
    "            clf.fit(x, y)\n",
    "            return clf\n",
    "        \n",
    "        clf_by_rules = {}\n",
    "        x_for_indices_calculation = pd.DataFrame(x)\n",
    "        for col in range(x_for_indices_calculation.shape[1]):\n",
    "            x_for_indices_calculation[f\"col{col}\"] = x_for_indices_calculation[col]\n",
    "        indices_by_each_statement = {\n",
    "            query: x_for_indices_calculation.query(query).index for query in statements\n",
    "        }\n",
    "\n",
    "        simple_areas = 0\n",
    "        for query, idx in indices_by_each_statement.items():\n",
    "            x_train = x[idx]\n",
    "            y_train = y[idx]\n",
    "        \n",
    "        \n",
    "            if len(np.unique(y_train)) == 1:\n",
    "                clf_by_rules[query] = DummyClassifier(strategy=\"constant\", constant=y_train[0]).fit(x_train, y_train)\n",
    "                simple_areas = simple_areas + 1\n",
    "            else:\n",
    "                if self.rf_to_explain is not None:\n",
    "                    tree, acc = find_best_tree(self.rf_to_explain, x_train, y_train)\n",
    "                    clf_by_rules[query] = tree\n",
    "                else:\n",
    "                    clf = clone(self.base_clf)\n",
    "                    clf.fit(x_train, y_train)\n",
    "                    clf_by_rules[query] = clf\n",
    "        \n",
    "        self.clf_by_rules_ = clf_by_rules\n",
    "        self.classes_ = np.unique(y)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def predict(self, x):\n",
    "        check_is_fitted(self)\n",
    "        \n",
    "        df = pd.DataFrame(x, columns=[f\"col{i}\" for i in range(x.shape[1])])\n",
    "    \n",
    "        for rule, clf in self.clf_by_rules_.items():\n",
    "            idx_to_predict = df.query(rule).index\n",
    "            to_predict = df.loc[idx_to_predict] \\\n",
    "                .drop('prediction', axis=1, errors='ignore') \\\n",
    "                .drop('rule', axis=1, errors='ignore') \\\n",
    "                .to_numpy()\n",
    "    \n",
    "            if len(to_predict) == 0:\n",
    "                continue\n",
    "    \n",
    "            df.loc[idx_to_predict, 'prediction'] = clf.predict(df.loc[df.query(rule).index] \\\n",
    "                                                               .drop('prediction', axis=1, errors='ignore') \\\n",
    "                                                               .drop('rule', axis=1, errors='ignore') \\\n",
    "                                                               .to_numpy())\n",
    "            df.loc[df.query(rule).index, 'rule'] = rule\n",
    "    \n",
    "        return df.prediction.to_numpy()"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-07-27T14:16:48.969133Z",
     "start_time": "2024-07-27T14:16:48.949711Z"
    }
   },
   "source": [
    "def experiment_quad_split(run_id):\n",
    "    params, client = get_params_and_client(run_id)\n",
    "    params = Box(params,  box_recast={\n",
    "        'min_split_percentage': float,\n",
    "        'min_samples': int\n",
    "    })\n",
    "    log.info(params)\n",
    "\n",
    "    base_clf = MODELS.get(params.base_clf)\n",
    "    complexity_measure_func = COMPLEXITY_METRICS.get(params.complexity_measure)\n",
    "    \n",
    "    log.info(params)\n",
    "\n",
    "    try:\n",
    "        x_train, y_train, x_test, y_test = get_dataset(params)\n",
    "\n",
    "        # model\n",
    "        model = QuadSplitClassifier(\n",
    "            base_clf=base_clf, \n",
    "            min_samples=params.min_samples,\n",
    "            minimal_split_percentage=params.min_split_percentage,\n",
    "            complexity_measure=complexity_measure_func, \n",
    "            recursion_limit=50\n",
    "        )\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "        metrics = calculate_metrics_qs(model)\n",
    "        client.log_dict(run_id, metrics, f'quad_split.json')\n",
    "        \n",
    "        calculate_and_log_classification_metrics(y_test, y_pred, client, run_id)\n",
    "\n",
    "        terminate_run(run_id, client=client)\n",
    "        log.info(\"Run finished\")\n",
    "    except Exception as e:\n",
    "        finish_run_and_print_exception(run_id, e, client = client)"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T14:16:48.989267Z",
     "start_time": "2024-07-27T14:16:48.970031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def experiment_quad_split_explain(run_id):\n",
    "    params, client = get_params_and_client(run_id)\n",
    "    params = Box(params,  box_recast={\n",
    "        'min_split_percentage': float,\n",
    "        'min_samples': int,\n",
    "        'n_estimators': int,\n",
    "    })\n",
    "    log.info(params)\n",
    "\n",
    "    try:\n",
    "        x_train, y_train, x_test, y_test = get_dataset(params)\n",
    "\n",
    "        complexity_measure_func = COMPLEXITY_METRICS.get(params.complexity_measure)\n",
    "\n",
    "        rf = RandomForestClassifier(random_state=42, **DT_PARAMS, n_estimators=params.n_estimators)\n",
    "        rf.fit(x_train, y_train)\n",
    "        # model\n",
    "        model = QuadSplitClassifier(\n",
    "            rf_to_explain=rf,\n",
    "            min_samples=params.min_samples,\n",
    "            minimal_split_percentage=params.min_split_percentage,\n",
    "            complexity_measure=complexity_measure_func,\n",
    "            recursion_limit=50\n",
    "        )\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "        metrics = calculate_metrics_qs(model)\n",
    "        client.log_dict(run_id, metrics, f'quad_split.json')\n",
    "        \n",
    "        calculate_and_log_classification_metrics(y_test, y_pred, client, run_id)\n",
    "\n",
    "\n",
    "        terminate_run(run_id, client=client)\n",
    "        log.info(\"Run finished\")\n",
    "    except Exception as e:\n",
    "        finish_run_and_print_exception(run_id, e, client = client)"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T14:16:49.009724Z",
     "start_time": "2024-07-27T14:16:48.990265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def experiment_quad_split_explain_2(run_id):\n",
    "    params, client = get_params_and_client(run_id)\n",
    "    params = Box(params,  box_recast={\n",
    "        'min_split_percentage': float,\n",
    "        'min_samples': int,\n",
    "    })\n",
    "    log.info(params)\n",
    "\n",
    "    try:\n",
    "        x_train, y_train, x_test, y_test = get_dataset(params)\n",
    "\n",
    "        base_clf = MODELS.get(params.base_clf)\n",
    "        complexity_measure_func = COMPLEXITY_METRICS.get(params.complexity_measure)\n",
    "\n",
    "        rf = RandomForestClassifier(random_state=42, **RF_PARAMS, **DT_PARAMS)\n",
    "        # model\n",
    "        rf.fit(x_train, y_train)\n",
    "        \n",
    "        model = QuadSplitClassifier(\n",
    "            base_clf=base_clf,\n",
    "            min_samples=params.min_samples,\n",
    "            minimal_split_percentage=params.min_split_percentage,\n",
    "            complexity_measure=complexity_measure_func,\n",
    "            recursion_limit=50\n",
    "        )\n",
    "        model.fit(x_train, rf.predict(x_train))\n",
    "\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "        metrics = calculate_metrics_qs(model)\n",
    "        client.log_dict(run_id, metrics, f'quad_split.json')\n",
    "\n",
    "        calculate_and_log_classification_metrics(y_test, y_pred, client, run_id)\n",
    "        \n",
    "        terminate_run(run_id, client=client)\n",
    "        log.info(\"Run finished\")\n",
    "    except Exception as e:\n",
    "        finish_run_and_print_exception(run_id, e, client = client)"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-07-27T14:16:49.031148Z",
     "start_time": "2024-07-27T14:16:49.010408Z"
    }
   },
   "source": [
    "import sys\n",
    "log.remove(0)\n",
    "log.add(sys.stderr, level=\"INFO\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
